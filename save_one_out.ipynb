{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_pickle('data.pkl')\n",
    "except:\n",
    "    print('data frame not found',\n",
    "          'run prepare_dataframe.py')\n",
    "    \n",
    "scoring = []\n",
    "frame_length = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(column):\n",
    "    '''\n",
    "    elements in column are assumed to be np.arrays\n",
    "    returns series of splitted np.arrays (with overlap!)\n",
    "\n",
    "    '''\n",
    "    col = column.apply(librosa.util.frame, \n",
    "                 frame_length=frame_length, \n",
    "                 hop_length=frame_length)\n",
    "    col = col.apply(np.transpose).explode()\n",
    "    return col\n",
    "\n",
    "def mfccify(x):\n",
    "    '''\n",
    "    return mfcc of vector np.array x\n",
    "    '''\n",
    "    xmfcc = librosa.feature.mfcc(y=x, sr=8000,\n",
    "                                hop_length=1024, \n",
    "                                htk=True).flatten()\n",
    "    return xmfcc\n",
    "\n",
    "def cqtify(x):\n",
    "    '''\n",
    "    return cqt of vector np.array x\n",
    "    '''\n",
    "    xcqt = librosa.core.cqt(y=x, sr=8000,\n",
    "                             hop_length=1024,nbins=3).flatten()\n",
    "\n",
    "def sum_threshold(x, threshold=1600):\n",
    "    '''\n",
    "    x is assumed to be vector of 0s and 1s\n",
    "    returns 1 if more than threshold entries are active\n",
    "    '''\n",
    "    x = np.sum(x) > threshold\n",
    "    return float(x)\n",
    "\n",
    "def convert_to_numpy(series):\n",
    "    '''\n",
    "    takes pandas series of np.arrays\n",
    "    returns the np.matrix equivalent\n",
    "    '''\n",
    "    m, n = series.shape[0], series.iloc[0].shape[0]\n",
    "    D = np.zeros([m,n])\n",
    "    for idx, data in enumerate(series):\n",
    "        D[idx,:] = data\n",
    "    return D\n",
    "\n",
    "def evaluate(model,X_test,y_test):\n",
    "    '''\n",
    "    return testset roc_auc, accuracy and confusion matrix\n",
    "    '''\n",
    "    y_predict = model.predict(X_test)\n",
    "    roc = roc_auc_score(y_test, y_predict)\n",
    "    acc = accuracy_score(y_test, y_predict)\n",
    "    conf = confusion_matrix(y_test, y_predict)\n",
    "    return roc, acc, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6604122621564482\n",
      "[[1537   74]\n",
      " [  97   38]]\n",
      "0.6900386847195358\n",
      "[[1711   88]\n",
      " [ 109   48]]\n",
      "0.5848639455782313\n",
      "[[1888  107]\n",
      " [ 120   52]]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(30):\n",
    "    '''\n",
    "    cross validation of support vector machine on mfccs\n",
    "    whole data events (one train passes) are left out\n",
    "    for robust estimation (possible bleed of train info -> test info impossible)\n",
    "    '''\n",
    "    data_test = data.sample(5) # take 5 random rows\n",
    "    data_train = data.drop(data_test.index) # drop test from train\n",
    "\n",
    "    # expand, mfccify and convert to numpy\n",
    "    X_train = convert_to_numpy((expand(data_train['audio_content'])\n",
    "               .apply(mfccify)))\n",
    "    y_train = (expand(data_train['target_vector'])\n",
    "               .apply(sum_threshold)\n",
    "               .to_numpy())\n",
    "\n",
    "    X_test = convert_to_numpy((expand(data_test['audio_content'])\n",
    "               .apply(mfccify)))\n",
    "    y_test = (expand(data_test['target_vector'])\n",
    "              .apply(sum_threshold)\n",
    "              .to_numpy())\n",
    "\n",
    "\n",
    "    # support vector machine with radial basis with short kernel width (high complexity)\n",
    "    # use class weights to tackle imbalanced classes\n",
    "    clf = SVC(C=10, gamma=1e-06, \n",
    "              kernel='linear', tol=0.001,\n",
    "              class_weight='balanced',\n",
    "              probability=True)\n",
    "\n",
    "    # train / test model\n",
    "    clf.fit(X_train,y_train)\n",
    "    scoring.append(evaluate(clf, X_test, y_test))\n",
    "\n",
    "    # print roc_auc\n",
    "    print(scoring[-1][0])\n",
    "    conf_mats = []\n",
    "    for i in range(len(scoring)):\n",
    "        conf_mats.append(scoring[i][2])\n",
    "    conf_mats = np.array(conf_mats)\n",
    "    print(conf_mats.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = conf_mats.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70.58, 19.6 ],\n",
       "       [ 1.85,  7.96]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(conf_mat * 100 / np.sum(conf_mat),2) # confusion matrix in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785069825688323"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([run[0] for run in scoring]) # mean roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPORT:\n",
    "\n",
    "we find a mean roc_auc of approximately 0.80.\n",
    "\n",
    "\n",
    "Interpreting the confusion matrix we see :\n",
    "\n",
    "- a 1.5 % chance of\n",
    "our classifier to miss a faulty train. (False Positive)\n",
    "\n",
    "- there is a 19.3 % chance of a train classified\n",
    "as faulty, to actually be without harm. (False Negative)\n",
    "\n",
    "- 71.1 % percent of the audio was correctly classified as unsuspicious.\n",
    "\n",
    "- 8.2 % percent of the audio was correctly classified as suspicious"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
